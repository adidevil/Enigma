{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn import ensemble, linear_model, clone\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, BaggingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/Users/L3IN/Downloads/enigma18/train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/L3IN/Downloads/enigma18/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Username</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>330045.000000</td>\n",
       "      <td>3.300450e+05</td>\n",
       "      <td>330045.000000</td>\n",
       "      <td>330045.000000</td>\n",
       "      <td>3.300450e+05</td>\n",
       "      <td>330045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>235748.682789</td>\n",
       "      <td>7.773147e+03</td>\n",
       "      <td>3.917672</td>\n",
       "      <td>81442.888803</td>\n",
       "      <td>2.964507e+04</td>\n",
       "      <td>337.505358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>136039.418471</td>\n",
       "      <td>2.706141e+04</td>\n",
       "      <td>3.579515</td>\n",
       "      <td>49215.100730</td>\n",
       "      <td>8.095646e+04</td>\n",
       "      <td>3592.441135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117909.000000</td>\n",
       "      <td>2.820000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>39808.000000</td>\n",
       "      <td>2.594000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>235699.000000</td>\n",
       "      <td>1.236000e+03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79010.000000</td>\n",
       "      <td>8.954000e+03</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>353620.000000</td>\n",
       "      <td>5.118000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>122559.000000</td>\n",
       "      <td>2.687000e+04</td>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>471493.000000</td>\n",
       "      <td>1.042428e+06</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>175738.000000</td>\n",
       "      <td>5.231058e+06</td>\n",
       "      <td>615278.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID    Reputation        Answers       Username  \\\n",
       "count  330045.000000  3.300450e+05  330045.000000  330045.000000   \n",
       "mean   235748.682789  7.773147e+03       3.917672   81442.888803   \n",
       "std    136039.418471  2.706141e+04       3.579515   49215.100730   \n",
       "min         1.000000  0.000000e+00       0.000000       0.000000   \n",
       "25%    117909.000000  2.820000e+02       2.000000   39808.000000   \n",
       "50%    235699.000000  1.236000e+03       3.000000   79010.000000   \n",
       "75%    353620.000000  5.118000e+03       5.000000  122559.000000   \n",
       "max    471493.000000  1.042428e+06      76.000000  175738.000000   \n",
       "\n",
       "              Views        Upvotes  \n",
       "count  3.300450e+05  330045.000000  \n",
       "mean   2.964507e+04     337.505358  \n",
       "std    8.095646e+04    3592.441135  \n",
       "min    9.000000e+00       0.000000  \n",
       "25%    2.594000e+03       8.000000  \n",
       "50%    8.954000e+03      28.000000  \n",
       "75%    2.687000e+04     107.000000  \n",
       "max    5.231058e+06  615278.000000  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160728"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Reputation'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Username</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160728</th>\n",
       "      <td>199859</td>\n",
       "      <td>c</td>\n",
       "      <td>1042428.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>46604</td>\n",
       "      <td>14307.0</td>\n",
       "      <td>11844.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID Tag  Reputation  Answers  Username    Views  Upvotes\n",
       "160728  199859   c   1042428.0      4.0     46604  14307.0  11844.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[160728:160729]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98585"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Views'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Username</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98585</th>\n",
       "      <td>231439</td>\n",
       "      <td>j</td>\n",
       "      <td>15272.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>96201</td>\n",
       "      <td>5231058.0</td>\n",
       "      <td>144203.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID Tag  Reputation  Answers  Username      Views   Upvotes\n",
       "98585  231439   j     15272.0     32.0     96201  5231058.0  144203.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[98585:98586]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_repo = [-1,1000,10000,50000,100000,500000,1042430]\n",
    "bin_views = [0,1000,10000,50000,100000,500000,1000000,5231060]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train['Reputation'] = pd.cut(train['Reputation'].astype(int),bin_repo)\n",
    "#train['Views'] = pd.cut(train['Views'].astype(int),bin_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['new'] = test['Views']*test['Reputation']\n",
    "train['new'] = train['Views']*train['Reputation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Username</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84516</th>\n",
       "      <td>81151</td>\n",
       "      <td>s</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>45857.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Tag  Reputation  Answers  Username    Views  Upvotes  new\n",
       "84516  81151   s         0.0      2.0        60  45857.0      0.0  0.0"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['Username'] == 60 ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat(objs=[train, test], axis=0)\n",
    "train_l = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "dataset['Tag'] = lb_make.fit_transform(dataset['Tag'])\n",
    "dataset['Username'] = lb_make.fit_transform(dataset['Username'])\n",
    "#train['Reputation'] = lb_make.fit_transform(train['Reputation'])\n",
    "#train['Views'] = lb_make.fit_transform(train['Views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = dataset[:train_l]\n",
    "test = dataset[train_l:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answers</th>\n",
       "      <th>ID</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Username</th>\n",
       "      <th>Views</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>141448.000000</td>\n",
       "      <td>141448.000000</td>\n",
       "      <td>1.414480e+05</td>\n",
       "      <td>141448.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141448.000000</td>\n",
       "      <td>1.414480e+05</td>\n",
       "      <td>1.414480e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.914873</td>\n",
       "      <td>235743.073497</td>\n",
       "      <td>7.920927e+03</td>\n",
       "      <td>3.552542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81348.231117</td>\n",
       "      <td>2.984633e+04</td>\n",
       "      <td>3.220553e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.577460</td>\n",
       "      <td>136269.867118</td>\n",
       "      <td>2.791072e+04</td>\n",
       "      <td>2.494553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49046.098215</td>\n",
       "      <td>8.034374e+04</td>\n",
       "      <td>3.507001e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>117797.000000</td>\n",
       "      <td>2.860000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40222.750000</td>\n",
       "      <td>2.608000e+03</td>\n",
       "      <td>1.188850e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>235830.000000</td>\n",
       "      <td>1.245000e+03</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78795.500000</td>\n",
       "      <td>8.977000e+03</td>\n",
       "      <td>1.117894e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>353616.000000</td>\n",
       "      <td>5.123000e+03</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122149.000000</td>\n",
       "      <td>2.698925e+04</td>\n",
       "      <td>7.483872e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>471488.000000</td>\n",
       "      <td>1.042428e+06</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175737.000000</td>\n",
       "      <td>5.004669e+06</td>\n",
       "      <td>4.656757e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Answers             ID    Reputation            Tag  Upvotes  \\\n",
       "count  141448.000000  141448.000000  1.414480e+05  141448.000000      0.0   \n",
       "mean        3.914873  235743.073497  7.920927e+03       3.552542      NaN   \n",
       "std         3.577460  136269.867118  2.791072e+04       2.494553      NaN   \n",
       "min         0.000000       7.000000  0.000000e+00       0.000000      NaN   \n",
       "25%         2.000000  117797.000000  2.860000e+02       1.000000      NaN   \n",
       "50%         3.000000  235830.000000  1.245000e+03       4.000000      NaN   \n",
       "75%         5.000000  353616.000000  5.123000e+03       6.000000      NaN   \n",
       "max        73.000000  471488.000000  1.042428e+06       9.000000      NaN   \n",
       "\n",
       "            Username         Views           new  \n",
       "count  141448.000000  1.414480e+05  1.414480e+05  \n",
       "mean    81348.231117  2.984633e+04  3.220553e+08  \n",
       "std     49046.098215  8.034374e+04  3.507001e+09  \n",
       "min         4.000000  9.000000e+00  0.000000e+00  \n",
       "25%     40222.750000  2.608000e+03  1.188850e+06  \n",
       "50%     78795.500000  8.977000e+03  1.117894e+07  \n",
       "75%    122149.000000  2.698925e+04  7.483872e+07  \n",
       "max    175737.000000  5.004669e+06  4.656757e+11  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avr = train['Reputation'].mean()\n",
    "avv = train['Views'].mean()\n",
    "sr = train['Reputation'].std()\n",
    "sv = train['Views'].std()\n",
    "nr = train['new'].mean()\n",
    "nv = train['new'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#train['Answers'] = train['Answers']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "max_user = train['Username'].max()\n",
    "val = train.shape[0]\n",
    "\n",
    "for i in range(max_user+1):\n",
    "    d[i] = 0\n",
    "\n",
    "for i in range(val):\n",
    "    d[int(train.ix[i]['Username'])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['uv'] = train['Upvotes']/train['Views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = {}\n",
    "max_user = train['Username'].max()\n",
    "val = train.shape[0]\n",
    "\n",
    "for i in range(max_user+1):\n",
    "    v[i] = 0\n",
    "\n",
    "for i in range(val):\n",
    "    temp = train.ix[i]\n",
    "    uv = temp['uv']\n",
    "    x1 = int(temp['Username'])\n",
    "    v[x1] += uv/d[x1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Reputation'] = (train['Reputation'] - train['Reputation'].mean()) / (train['Reputation']).std()\n",
    "train['Views'] = (train['Views'] - train['Views'].mean()) / (train['Views']).std()\n",
    "train['new'] = (train['new'] - train['new'].mean()) / (train['new']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.00026673068203035398,\n",
       " 1: 0.0,\n",
       " 2: 3.6828343092844256e-05,\n",
       " 3: 0.003111148994203887,\n",
       " 4: 0,\n",
       " 5: 0.0048848569434752267,\n",
       " 6: 0.0065292096219931274,\n",
       " 7: 0,\n",
       " 8: 0,\n",
       " 9: 0.005763688760806916,\n",
       " 10: 3.0344869441199228e-05,\n",
       " 11: 2.4897918534010556e-05,\n",
       " 12: 0.0078131807487873597,\n",
       " 13: 0.021459227467811159,\n",
       " 14: 0.0010387451958034693,\n",
       " 15: 0,\n",
       " 16: 0,\n",
       " 17: 0.011097410604192354,\n",
       " 18: 0.010994502748625687,\n",
       " 19: 0,\n",
       " 20: 0,\n",
       " 21: 0.0,\n",
       " 22: 0.021897810218978103,\n",
       " 23: 0,\n",
       " 24: 0,\n",
       " 25: 0,\n",
       " 26: 0.0013404825737265416,\n",
       " 27: 0,\n",
       " 28: 0.0035325287017957019,\n",
       " 29: 0.00091095422455021637,\n",
       " 30: 0.0023617153511497823,\n",
       " 31: 0.0007326007326007326,\n",
       " 32: 0.00056122448979591837,\n",
       " 33: 0,\n",
       " 34: 0,\n",
       " 35: 0,\n",
       " 36: 0.0010604453870625664,\n",
       " 37: 0.015902712815715623,\n",
       " 38: 2.264077467674634e-06,\n",
       " 39: 8.0019204609106182e-05,\n",
       " 40: 0,\n",
       " 41: 6.5420764550668388e-05,\n",
       " 42: 0,\n",
       " 43: 0.000161138095347713,\n",
       " 44: 0,\n",
       " 45: 0,\n",
       " 46: 0.0076577571607392685,\n",
       " 47: 0.0005294927459493805,\n",
       " 48: 0,\n",
       " 49: 0.0037917959324370908,\n",
       " 50: 0.0027386541471048514,\n",
       " 51: 0,\n",
       " 52: 3.5429583702391498e-05,\n",
       " 53: 0,\n",
       " 54: 0.021726365237815619,\n",
       " 55: 5.3173105043469014e-05,\n",
       " 56: 0.00098039215686274508,\n",
       " 57: 0.004323447949739918,\n",
       " 58: 0.0013668204339654878,\n",
       " 59: 0.0,\n",
       " 60: 0.0,\n",
       " 61: 0.00084781687155574396,\n",
       " 62: 0.0012219787628518456,\n",
       " 63: 0.0010695187165775401,\n",
       " 64: 0.0031712473572938688,\n",
       " 65: 0.0,\n",
       " 66: 0.0036027082427479967,\n",
       " 67: 0.0009225092250922509,\n",
       " 68: 0.00071441045261871124,\n",
       " 69: 0.0011880515953835709,\n",
       " 70: 0.00052064844397112773,\n",
       " 71: 0,\n",
       " 72: 0.0008963473844085352,\n",
       " 73: 0,\n",
       " 74: 0,\n",
       " 75: 0.00045544253833308028,\n",
       " 76: 8.9468805806167625e-07,\n",
       " 77: 0.0011652122173740579,\n",
       " 78: 0,\n",
       " 79: 0.0020250952986022872,\n",
       " 80: 0,\n",
       " 81: 0.0034534180990503098,\n",
       " 82: 0,\n",
       " 83: 0,\n",
       " 84: 0.0011155290712482144,\n",
       " 85: 0.00015028554253080853,\n",
       " 86: 0.010582010582010581,\n",
       " 87: 0.0,\n",
       " 88: 0,\n",
       " 89: 0,\n",
       " 90: 0,\n",
       " 91: 0.0,\n",
       " 92: 0.00038000337780780274,\n",
       " 93: 0.0032454270989501328,\n",
       " 94: 0.0032715376226826608,\n",
       " 95: 0.00051444109649445135,\n",
       " 96: 0,\n",
       " 97: 0.0014921661278288984,\n",
       " 98: 0.019567384158622275,\n",
       " 99: 0,\n",
       " 100: 0.0021587194845101628,\n",
       " 101: 0.0016785564414603441,\n",
       " 102: 0.0025081520751637498,\n",
       " 103: 0.0036181299773866875,\n",
       " 104: 0.051081736965654566,\n",
       " 105: 0.0,\n",
       " 106: 0.052083333333333336,\n",
       " 107: 0.0041988578485751956,\n",
       " 108: 0.0054920262090456338,\n",
       " 109: 0.00043528728961114336,\n",
       " 110: 0.0073099757137479963,\n",
       " 111: 0.00074460163812360388,\n",
       " 112: 0.00033339182312686435,\n",
       " 113: 0.0023935185583786062,\n",
       " 114: 0.0089561727571967169,\n",
       " 115: 0.0015955325089748703,\n",
       " 116: 0.0020695364238410598,\n",
       " 117: 0.0020468501250852852,\n",
       " 118: 0.0053338505552053533,\n",
       " 119: 0,\n",
       " 120: 0.0010653295206097596,\n",
       " 121: 0.0007560160986065836,\n",
       " 122: 0.012658227848101266,\n",
       " 123: 0,\n",
       " 124: 0.0010661777261705542,\n",
       " 125: 0.012195121951219513,\n",
       " 126: 0.0039339103068450039,\n",
       " 127: 0.00080048146908612023,\n",
       " 128: 0.012557077625570776,\n",
       " 129: 0,\n",
       " 130: 0.00086248913543586644,\n",
       " 131: 0.028169014084507043,\n",
       " 132: 0,\n",
       " 133: 0.0015637608390985038,\n",
       " 134: 0.00026820437173125924,\n",
       " 135: 0.002216281673406905,\n",
       " 136: 0,\n",
       " 137: 0,\n",
       " 138: 0.0047169811320754715,\n",
       " 139: 0.0020509406134603765,\n",
       " 140: 0,\n",
       " 141: 0.00054850874185807341,\n",
       " 142: 0.058608058608058608,\n",
       " 143: 0.004506065857885615,\n",
       " 144: 0.01647573690307633,\n",
       " 145: 0.00036337209302325581,\n",
       " 146: 0.0021953896816684962,\n",
       " 147: 0,\n",
       " 148: 0,\n",
       " 149: 0.006582884500299222,\n",
       " 150: 0.0061791967044284241,\n",
       " 151: 0.010340227249493171,\n",
       " 152: 0.001483679525222552,\n",
       " 153: 0.039215686274509803,\n",
       " 154: 0.00097560975609756097,\n",
       " 155: 0.0014232039166571786,\n",
       " 156: 0.0045002868758456018,\n",
       " 157: 0.0024753240288465216,\n",
       " 158: 0.00064814648110472967,\n",
       " 159: 0.0012360939431396785,\n",
       " 160: 0.0,\n",
       " 161: 0.0034657150250803513,\n",
       " 162: 0.001850613154960981,\n",
       " 163: 0.021264626462646263,\n",
       " 164: 0.0020056827678422194,\n",
       " 165: 0,\n",
       " 166: 0.00025764342150463756,\n",
       " 167: 0.00043535045711797995,\n",
       " 168: 0,\n",
       " 169: 0,\n",
       " 170: 0.0033720600736752621,\n",
       " 171: 0.010657193605683837,\n",
       " 172: 0.0013793103448275861,\n",
       " 173: 0.06682678928034648,\n",
       " 174: 0.0040408924500932517,\n",
       " 175: 0.011289343798041912,\n",
       " 176: 0.011054872798341267,\n",
       " 177: 0,\n",
       " 178: 0.0012319822594554638,\n",
       " 179: 0.0036248285265334836,\n",
       " 180: 0.0024982966159436746,\n",
       " 181: 0.0051534842034505939,\n",
       " 182: 0.0012774281387466615,\n",
       " 183: 0.024646464646464646,\n",
       " 184: 0.0065996228786926459,\n",
       " 185: 0.017201414379151642,\n",
       " 186: 0.013683594519937009,\n",
       " 187: 0.008771929824561403,\n",
       " 188: 0.0052782736940153695,\n",
       " 189: 0.0057050767846063945,\n",
       " 190: 0.0010791014028318237,\n",
       " 191: 0.02772543741588156,\n",
       " 192: 0.0055134490650930509,\n",
       " 193: 0.0058636394696360396,\n",
       " 194: 0.0045197826164821552,\n",
       " 195: 0.0011620401261155312,\n",
       " 196: 0,\n",
       " 197: 0.0010529151056588065,\n",
       " 198: 0.0022665457842248413,\n",
       " 199: 0.0098910029607374231,\n",
       " 200: 0.009154658446298123,\n",
       " 201: 0.0003993078663649674,\n",
       " 202: 0.0039466760217505698,\n",
       " 203: 0.0033640448350153308,\n",
       " 204: 0.01065938764318033,\n",
       " 205: 0.064764736609474821,\n",
       " 206: 0.025047821338838754,\n",
       " 207: 0.017323297981476748,\n",
       " 208: 0,\n",
       " 209: 0.00024807740014884643,\n",
       " 210: 0.0022759286969183741,\n",
       " 211: 0.0078636959370904317,\n",
       " 212: 0.00031170450413008468,\n",
       " 213: 0.0044262888913052835,\n",
       " 214: 0.0175454813009654,\n",
       " 215: 0.00071205564988771435,\n",
       " 216: 0.0096645821489482666,\n",
       " 217: 0.0082773662843786087,\n",
       " 218: 0.0020730640728664641,\n",
       " 219: 0.00070509430636347611,\n",
       " 220: 0.0024705105036906603,\n",
       " 221: 0.035879629629629629,\n",
       " 222: 0.0053918128654970761,\n",
       " 223: 0.039925157752518446,\n",
       " 224: 0.001382234871862465,\n",
       " 225: 0.0019099933581058037,\n",
       " 226: 0.00315867707172055,\n",
       " 227: 0,\n",
       " 228: 0,\n",
       " 229: 0.0044645076714123445,\n",
       " 230: 0,\n",
       " 231: 0.0068108222226218127,\n",
       " 232: 0.00080469224803472543,\n",
       " 233: 0.00075892233029098682,\n",
       " 234: 0.00170599858293498,\n",
       " 235: 0.0011623800835736566,\n",
       " 236: 0.0042589437819420782,\n",
       " 237: 0.0036347408482222416,\n",
       " 238: 0.0021361793385383508,\n",
       " 239: 0,\n",
       " 240: 0.017024204957472405,\n",
       " 241: 0.033333333333333333,\n",
       " 242: 0.0017955544548325182,\n",
       " 243: 0.0054644808743169399,\n",
       " 244: 0.0070309638942228254,\n",
       " 245: 0.011889035667107001,\n",
       " 246: 0.0006740815638692282,\n",
       " 247: 0.0,\n",
       " 248: 0.005138537109524906,\n",
       " 249: 0.0054157878425137185,\n",
       " 250: 0.0011299435028248588,\n",
       " 251: 0.0016775040084061948,\n",
       " 252: 0.056603773584905662,\n",
       " 253: 0.0024438876451456678,\n",
       " 254: 0,\n",
       " 255: 0.0039038239730281254,\n",
       " 256: 0.0010579771476936098,\n",
       " 257: 0.0062656165298679428,\n",
       " 258: 0,\n",
       " 259: 0,\n",
       " 260: 0.0015977506023380965,\n",
       " 261: 0.015873015873015872,\n",
       " 262: 0.0,\n",
       " 263: 0.00045837917125045839,\n",
       " 264: 0,\n",
       " 265: 0.0048804732225216866,\n",
       " 266: 0.0017170389150004248,\n",
       " 267: 0.0015117157974300832,\n",
       " 268: 0.00073855243722304289,\n",
       " 269: 0.00052603892688058915,\n",
       " 270: 0.00058225971253397758,\n",
       " 271: 0.0008413359608031596,\n",
       " 272: 0.0050556117290192111,\n",
       " 273: 0.0021267168808152413,\n",
       " 274: 0.0030812963949587561,\n",
       " 275: 0,\n",
       " 276: 0.0011162804669638349,\n",
       " 277: 0.0019716088328075709,\n",
       " 278: 0.0028258565877781702,\n",
       " 279: 0.0028983980454163017,\n",
       " 280: 0.0032009258398121394,\n",
       " 281: 0.0098470684872321735,\n",
       " 282: 0,\n",
       " 283: 0.0044052863436123352,\n",
       " 284: 0.0061797752808988764,\n",
       " 285: 0.0028363908601905484,\n",
       " 286: 0.0013198061194586725,\n",
       " 287: 0.0010399629374207861,\n",
       " 288: 0.0,\n",
       " 289: 0.0005717552887364208,\n",
       " 290: 0.0,\n",
       " 291: 0,\n",
       " 292: 0.010128458498023716,\n",
       " 293: 0,\n",
       " 294: 0.004323015735777278,\n",
       " 295: 0.002219801227291401,\n",
       " 296: 0.0044788791764260958,\n",
       " 297: 0,\n",
       " 298: 0.11512829491550855,\n",
       " 299: 0.0082183005761511906,\n",
       " 300: 0.016696174297011174,\n",
       " 301: 0.0024754332008101419,\n",
       " 302: 0.0026926701671378841,\n",
       " 303: 0.00085846734962513594,\n",
       " 304: 0.00061924105815912018,\n",
       " 305: 0.012447508264351561,\n",
       " 306: 0.0026212319790301442,\n",
       " 307: 0.0021505376344086021,\n",
       " 308: 0.003790775121755954,\n",
       " 309: 0.0020112204932782895,\n",
       " 310: 0.0028985507246376812,\n",
       " 311: 0.0027341079972658922,\n",
       " 312: 0.00080707148347425057,\n",
       " 313: 0.0010650707511284678,\n",
       " 314: 0,\n",
       " 315: 0,\n",
       " 316: 0.0013541774075176674,\n",
       " 317: 0.003107283588806757,\n",
       " 318: 0.0016650068287035187,\n",
       " 319: 0,\n",
       " 320: 0.0011304544426859599,\n",
       " 321: 0,\n",
       " 322: 0.039855072463768113,\n",
       " 323: 0.0019284543438434095,\n",
       " 324: 0.0037422037422037424,\n",
       " 325: 0.00095072751322751317,\n",
       " 326: 0.00079428117553613975,\n",
       " 327: 0.0036622583926754831,\n",
       " 328: 0.0041390728476821195,\n",
       " 329: 0,\n",
       " 330: 0.0016871666485250899,\n",
       " 331: 0.0015635614006681323,\n",
       " 332: 0.0039032006245120999,\n",
       " 333: 0,\n",
       " 334: 0.002973240832507433,\n",
       " 335: 0,\n",
       " 336: 0,\n",
       " 337: 0.020259186351706038,\n",
       " 338: 0.00087438064704167882,\n",
       " 339: 0.0011839924224484964,\n",
       " 340: 0.0061833125380905919,\n",
       " 341: 0.0038930976430976432,\n",
       " 342: 0,\n",
       " 343: 0.0012185055618882906,\n",
       " 344: 0.0037370850736425589,\n",
       " 345: 0.011811023622047244,\n",
       " 346: 0.002889364561221925,\n",
       " 347: 0.0056669052732044858,\n",
       " 348: 0.0016051364365971107,\n",
       " 349: 0.0057093436285951867,\n",
       " 350: 0.00040590593130042114,\n",
       " 351: 0.0016260162601626016,\n",
       " 352: 0.018292682926829267,\n",
       " 353: 0.046153846153846156,\n",
       " 354: 0.0015444932873945585,\n",
       " 355: 0.00037119524870081661,\n",
       " 356: 0.00038275418979139897,\n",
       " 357: 0,\n",
       " 358: 0.0062642369020501137,\n",
       " 359: 0,\n",
       " 360: 0,\n",
       " 361: 0.0012971462781879864,\n",
       " 362: 0.0014272417002792429,\n",
       " 363: 0.010518790677613415,\n",
       " 364: 0.00084708843603272183,\n",
       " 365: 0.00044182238740026511,\n",
       " 366: 0,\n",
       " 367: 0.039247773486847722,\n",
       " 368: 0,\n",
       " 369: 0.00038875210574057279,\n",
       " 370: 0.0023187852806099336,\n",
       " 371: 0.0028896514357955572,\n",
       " 372: 0.01066886372448214,\n",
       " 373: 0,\n",
       " 374: 0.0026412325752017607,\n",
       " 375: 0.0080213903743315516,\n",
       " 376: 0,\n",
       " 377: 0.0032170739888185301,\n",
       " 378: 0.0019253613620045108,\n",
       " 379: 0.0014728483606557376,\n",
       " 380: 0,\n",
       " 381: 0.0088214344419483871,\n",
       " 382: 0,\n",
       " 383: 0.012430939226519336,\n",
       " 384: 0.001440079939131315,\n",
       " 385: 0.0052202965128419297,\n",
       " 386: 0.00036185996019540438,\n",
       " 387: 0.00094264375317235874,\n",
       " 388: 0.0022026431718061676,\n",
       " 389: 0.0033965216260505205,\n",
       " 390: 0.010711893878113428,\n",
       " 391: 0.0010836616599813147,\n",
       " 392: 0.0035842293906810036,\n",
       " 393: 0.00092336103416435823,\n",
       " 394: 0.0,\n",
       " 395: 0.016872003112996761,\n",
       " 396: 0,\n",
       " 397: 0.0033239106679838208,\n",
       " 398: 0.00060579671733903791,\n",
       " 399: 0.0034860954781353094,\n",
       " 400: 0.0029765148470190673,\n",
       " 401: 0.0012321593592771332,\n",
       " 402: 0.0088407368932086772,\n",
       " 403: 0.0032418914120752734,\n",
       " 404: 0.0020544427324088342,\n",
       " 405: 0,\n",
       " 406: 0.00641627299366203,\n",
       " 407: 0.0011987794245858763,\n",
       " 408: 0.020944402132520946,\n",
       " 409: 0,\n",
       " 410: 0.0061983471074380167,\n",
       " 411: 0,\n",
       " 412: 0.0038910505836575876,\n",
       " 413: 0,\n",
       " 414: 0,\n",
       " 415: 0.0014760504760867725,\n",
       " 416: 0.022292993630573247,\n",
       " 417: 0.0038214431071573931,\n",
       " 418: 0.00050725372831490311,\n",
       " 419: 0.00071126191001354751,\n",
       " 420: 0.0022563176895306859,\n",
       " 421: 0.0019477585180828661,\n",
       " 422: 0.0052121584277232966,\n",
       " 423: 0,\n",
       " 424: 0.0033670033670033669,\n",
       " 425: 0.00020048115477145148,\n",
       " 426: 0,\n",
       " 427: 0.0054461148260335334,\n",
       " 428: 0.00026816840976133012,\n",
       " 429: 0.00086225479629230435,\n",
       " 430: 0.0019798787151473953,\n",
       " 431: 0.02,\n",
       " 432: 0,\n",
       " 433: 0.0020023664330572496,\n",
       " 434: 0.0076710261569416498,\n",
       " 435: 0.0030497665732402779,\n",
       " 436: 0.0043903515836974678,\n",
       " 437: 0.0076481835564053535,\n",
       " 438: 0.028081994059371465,\n",
       " 439: 0.00087393489185055709,\n",
       " 440: 0.0062111801242236021,\n",
       " 441: 0.00023822285748317551,\n",
       " 442: 0.0037517775558984601,\n",
       " 443: 0.0060606060606060606,\n",
       " 444: 0.0037962670041126224,\n",
       " 445: 0.0030068334031895403,\n",
       " 446: 0,\n",
       " 447: 0.0,\n",
       " 448: 0.004434589800443459,\n",
       " 449: 0.031746031746031744,\n",
       " 450: 0.00519311911716975,\n",
       " 451: 0.00047251535674909436,\n",
       " 452: 0.0012661613590282841,\n",
       " 453: 0,\n",
       " 454: 0,\n",
       " 455: 0,\n",
       " 456: 0,\n",
       " 457: 0.023480401233741514,\n",
       " 458: 0,\n",
       " 459: 0.39784946236559138,\n",
       " 460: 0.047619047619047616,\n",
       " 461: 0.0013209104847269725,\n",
       " 462: 0,\n",
       " 463: 0.001839878519409022,\n",
       " 464: 0.0075361614197155709,\n",
       " 465: 0,\n",
       " 466: 0.00044894637896686216,\n",
       " 467: 0.0084210526315789472,\n",
       " 468: 0.0041452497005526751,\n",
       " 469: 0,\n",
       " 470: 0,\n",
       " 471: 0,\n",
       " 472: 0.0011462719183307419,\n",
       " 473: 0.0030483052462026085,\n",
       " 474: 0,\n",
       " 475: 0.0006406149903907751,\n",
       " 476: 0,\n",
       " 477: 0.0059031284378315684,\n",
       " 478: 0.0087429111531190928,\n",
       " 479: 0,\n",
       " 480: 0.017297297297297298,\n",
       " 481: 0.0082110361966879555,\n",
       " 482: 0,\n",
       " 483: 0.0089666484417714604,\n",
       " 484: 0,\n",
       " 485: 0,\n",
       " 486: 0.024879967810087261,\n",
       " 487: 0,\n",
       " 488: 0.011476000622955994,\n",
       " 489: 0,\n",
       " 490: 0.0029850746268656717,\n",
       " 491: 0.0045027277119348372,\n",
       " 492: 0.0,\n",
       " 493: 0.0016769382953409407,\n",
       " 494: 0,\n",
       " 495: 0,\n",
       " 496: 0.040540540540540543,\n",
       " 497: 0.25477027443754041,\n",
       " 498: 0.0069364433457159433,\n",
       " 499: 0.0062383374120526152,\n",
       " 500: 0.0080801551389786692,\n",
       " 501: 0.0012054794520547944,\n",
       " 502: 0,\n",
       " 503: 0.017383414699637053,\n",
       " 504: 0.00038080731150038082,\n",
       " 505: 0.0083160083160083165,\n",
       " 506: 0,\n",
       " 507: 0.0011711125569290827,\n",
       " 508: 0.0,\n",
       " 509: 0.0026733783718568657,\n",
       " 510: 0.00019093392097133788,\n",
       " 511: 0,\n",
       " 512: 0.10714285714285714,\n",
       " 513: 0.0023151125401929262,\n",
       " 514: 0,\n",
       " 515: 0.002773594190363997,\n",
       " 516: 0.0013352408202193611,\n",
       " 517: 0.001277139208173691,\n",
       " 518: 0.0026185522634335316,\n",
       " 519: 0.0059425684863739859,\n",
       " 520: 0.0094284669536886332,\n",
       " 521: 0.053305148507756792,\n",
       " 522: 0,\n",
       " 523: 0.00045924225028702641,\n",
       " 524: 0.002397584655458205,\n",
       " 525: 0.0056700225461526442,\n",
       " 526: 0.0050036032797105114,\n",
       " 527: 0.0020790020790020791,\n",
       " 528: 0.0087175310112332649,\n",
       " 529: 0,\n",
       " 530: 0.00038501026694045176,\n",
       " 531: 0.025211355933352463,\n",
       " 532: 0.0024602573807721425,\n",
       " 533: 0.0085784167961327918,\n",
       " 534: 0.00043132180527781044,\n",
       " 535: 0,\n",
       " 536: 0.041666666666666664,\n",
       " 537: 0.00044802867383512545,\n",
       " 538: 0.0025231286795626578,\n",
       " 539: 0.019312071012156849,\n",
       " 540: 0.00055372557278865931,\n",
       " 541: 0.00070331731332786307,\n",
       " 542: 0.00080305715551617191,\n",
       " 543: 0.00014566642388929351,\n",
       " 544: 0.0089085093692094289,\n",
       " 545: 0.0021505376344086021,\n",
       " 546: 0.00460157718695585,\n",
       " 547: 0,\n",
       " 548: 0.00030894922934331125,\n",
       " 549: 0.00028551034975017847,\n",
       " 550: 0.0080789946140035901,\n",
       " 551: 0,\n",
       " 552: 0.0070647023347979671,\n",
       " 553: 0,\n",
       " 554: 0.012974051896207584,\n",
       " 555: 0.0046189376443418013,\n",
       " 556: 0.0005540102847745804,\n",
       " 557: 0.00084080717488789242,\n",
       " 558: 0.00031386604500940332,\n",
       " 559: 0,\n",
       " 560: 0.067789981834084634,\n",
       " 561: 0.0098874186451124342,\n",
       " 562: 0.0064935064935064939,\n",
       " 563: 0.0011007154650522839,\n",
       " 564: 0.0071942446043165471,\n",
       " 565: 0.0035820702524981983,\n",
       " 566: 0.00063952248987422724,\n",
       " 567: 0.01794289830644015,\n",
       " 568: 0.0056621826479361665,\n",
       " 569: 0.0070101443169231096,\n",
       " 570: 0.0013632739151683514,\n",
       " 571: 0.00012051096649795132,\n",
       " 572: 0,\n",
       " 573: 0.0026766595289079227,\n",
       " 574: 0.00022373867322966775,\n",
       " 575: 0.0032432432432432431,\n",
       " 576: 0.013274336283185841,\n",
       " 577: 0.0017084282460136675,\n",
       " 578: 0,\n",
       " 579: 0.00079817559863169893,\n",
       " 580: 0.0014634219873337492,\n",
       " 581: 0.010543852462204958,\n",
       " 582: 0,\n",
       " 583: 0.00052687038988408848,\n",
       " 584: 0.0,\n",
       " 585: 0,\n",
       " 586: 0.0017808569275177769,\n",
       " 587: 0.0066252028123309891,\n",
       " 588: 0,\n",
       " 589: 0.00076752515776906021,\n",
       " 590: 0.0059349522053763308,\n",
       " 591: 0,\n",
       " 592: 0.00037108356400690013,\n",
       " 593: 0.0037305366588921435,\n",
       " 594: 0.0033881897386253629,\n",
       " 595: 0.0021334958854007926,\n",
       " 596: 0.0024043277900220395,\n",
       " 597: 0,\n",
       " 598: 0.0014814814814814814,\n",
       " 599: 0.002553191489361702,\n",
       " 600: 0.00018706740662218619,\n",
       " 601: 0.0071932602881890663,\n",
       " 602: 0.0045520023048112937,\n",
       " 603: 0.00093576408533491248,\n",
       " 604: 0.0054867256637168137,\n",
       " 605: 0,\n",
       " 606: 0.00696227656194173,\n",
       " 607: 0.0080715744432558589,\n",
       " 608: 0,\n",
       " 609: 0.014503816793893129,\n",
       " 610: 0.0014910073618488492,\n",
       " 611: 0.034641584309485766,\n",
       " 612: 0.0042367441263320071,\n",
       " 613: 0.004398333443316603,\n",
       " 614: 0.00081424936386768443,\n",
       " 615: 0.0035377358490566039,\n",
       " 616: 0.00759947199698284,\n",
       " 617: 0.0054588645778140205,\n",
       " 618: 0,\n",
       " 619: 0.0051020408163265302,\n",
       " 620: 0.00079748471487629824,\n",
       " 621: 0,\n",
       " 622: 0.013144058885383806,\n",
       " 623: 0.0052231718898385565,\n",
       " 624: 0.0086288648244250334,\n",
       " 625: 0.0058319054450277066,\n",
       " 626: 0.040648460728327673,\n",
       " 627: 0.0030581039755351682,\n",
       " 628: 0.012842465753424657,\n",
       " 629: 0,\n",
       " 630: 0,\n",
       " 631: 0.004921522463278997,\n",
       " 632: 0.0011393847322445879,\n",
       " 633: 0.001053740779768177,\n",
       " 634: 0.0016390218317707992,\n",
       " 635: 0,\n",
       " 636: 0.0019852298896212181,\n",
       " 637: 0,\n",
       " 638: 0.0022227421619092184,\n",
       " 639: 0.0023594180102241447,\n",
       " 640: 0.001925498037473154,\n",
       " 641: 0.00025813113061435211,\n",
       " 642: 0.010662604722010662,\n",
       " 643: 0.0020186430471879988,\n",
       " 644: 0.0031601326425612828,\n",
       " 645: 0.0020942594219489036,\n",
       " 646: 0.00057627829002514664,\n",
       " 647: 0.00056728923023215225,\n",
       " 648: 0,\n",
       " 649: 0.0009554520482503284,\n",
       " 650: 0.0059859405368952942,\n",
       " 651: 0.0039432176656151417,\n",
       " 652: 0.0009779107225034514,\n",
       " 653: 0.0025112038324833874,\n",
       " 654: 0.0041876262545634344,\n",
       " 655: 0.00083542188805346695,\n",
       " 656: 0.00024588148512417015,\n",
       " 657: 0.096930533117932149,\n",
       " 658: 0.0053942037560040746,\n",
       " 659: 0.0019224273672620602,\n",
       " 660: 0.0022130013831258644,\n",
       " 661: 0.019736842105263157,\n",
       " 662: 0,\n",
       " 663: 0.0012836970474967907,\n",
       " 664: 0.0074557315936626279,\n",
       " 665: 0.0007510729613733906,\n",
       " 666: 0.009765625,\n",
       " 667: 0.0085688706995779504,\n",
       " 668: 0.0021858843328434957,\n",
       " 669: 0.022477013328714809,\n",
       " 670: 0.008374597396452077,\n",
       " 671: 0.0050505050505050509,\n",
       " 672: 0,\n",
       " 673: 0.00094743965711707647,\n",
       " 674: 0,\n",
       " 675: 0.00111915242856077,\n",
       " 676: 0.069444444444444448,\n",
       " 677: 0.00065656289325381626,\n",
       " 678: 0.16336488370386676,\n",
       " 679: 0.0015441157548312942,\n",
       " 680: 0.0069424631478839753,\n",
       " 681: 0.00070579931772732623,\n",
       " 682: 0,\n",
       " 683: 0,\n",
       " 684: 9.8697196999605207e-05,\n",
       " 685: 0.0013238858847659891,\n",
       " 686: 0.0013504388926401081,\n",
       " 687: 0.0051369863013698627,\n",
       " 688: 0.0010175527855507504,\n",
       " 689: 0.0010249183268208316,\n",
       " 690: 0.0057471985149247073,\n",
       " 691: 0,\n",
       " 692: 0.0041816703449878033,\n",
       " 693: 0.012889370767998164,\n",
       " 694: 0,\n",
       " 695: 0.0038240917782026767,\n",
       " 696: 0.0011051759071652237,\n",
       " 697: 0.0016072002571520412,\n",
       " 698: 0.0070767708789773081,\n",
       " 699: 0.00084961767204757861,\n",
       " 700: 0.00045892611289582378,\n",
       " 701: 0.013016157989228007,\n",
       " 702: 0.0068192888455918168,\n",
       " 703: 0.0022893772893772895,\n",
       " 704: 0,\n",
       " 705: 0.0,\n",
       " 706: 3.0421643985640983e-05,\n",
       " 707: 0.0011170444638186573,\n",
       " 708: 0.0024381095273818456,\n",
       " 709: 0.00073814356892415575,\n",
       " 710: 0.00044974139869574995,\n",
       " 711: 0.0070751965293171445,\n",
       " 712: 0.001200600300150075,\n",
       " 713: 0,\n",
       " 714: 0.00090650866280075329,\n",
       " 715: 0,\n",
       " 716: 0.0027051397655545538,\n",
       " 717: 0,\n",
       " 718: 0.0013940447660667574,\n",
       " 719: 0.0027398472112060172,\n",
       " 720: 0.00099173553719008266,\n",
       " 721: 0.007003317360855142,\n",
       " 722: 0,\n",
       " 723: 0.028633562885103298,\n",
       " 724: 0.00037407212578175229,\n",
       " 725: 0.0013060968601431482,\n",
       " 726: 0,\n",
       " 727: 0.0017464557222108075,\n",
       " 728: 0.0014415868988582631,\n",
       " 729: 0.065735172739063791,\n",
       " 730: 0,\n",
       " 731: 0.0016429353778751369,\n",
       " 732: 0.0027150441410688075,\n",
       " 733: 0,\n",
       " 734: 0.00013848497438027975,\n",
       " 735: 0.0017439626793166172,\n",
       " 736: 0.004367416555187565,\n",
       " 737: 0.0007657125974389555,\n",
       " 738: 0.0064876564876564877,\n",
       " 739: 0.002167434299647792,\n",
       " 740: 0.005744163782310921,\n",
       " 741: 0.0086234327283825542,\n",
       " 742: 0.00095894418619770503,\n",
       " 743: 0,\n",
       " 744: 0.0020537124802527647,\n",
       " 745: 0.002134133160964839,\n",
       " 746: 0,\n",
       " 747: 0.0026095193410631207,\n",
       " 748: 0.0068728522336769758,\n",
       " 749: 0.0068762278978389,\n",
       " 750: 0.0033670033670033669,\n",
       " 751: 0.003239541867820809,\n",
       " 752: 0,\n",
       " 753: 0.0022909507445589921,\n",
       " 754: 0.0019032513877874704,\n",
       " 755: 0.014211369095276221,\n",
       " 756: 0.001011378002528445,\n",
       " 757: 0.0045248868778280547,\n",
       " 758: 0.00020046106043900973,\n",
       " 759: 0.022757105268555601,\n",
       " 760: 0.011482939310484493,\n",
       " 761: 0,\n",
       " 762: 0.0042796005706134095,\n",
       " 763: 0.0051449526036942764,\n",
       " 764: 0.011779293242405457,\n",
       " 765: 0,\n",
       " 766: 0.00077849348953428507,\n",
       " 767: 0.0017887633140905765,\n",
       " 768: 0,\n",
       " 769: 0.02247191011235955,\n",
       " 770: 0,\n",
       " 771: 0.0027858730874124812,\n",
       " 772: 0.0026508323613614673,\n",
       " 773: 0.0027322404371584699,\n",
       " 774: 0.0090634441087613302,\n",
       " 775: 0.0005977286312014345,\n",
       " 776: 0,\n",
       " 777: 0.0012355848434925864,\n",
       " 778: 0,\n",
       " 779: 0,\n",
       " 780: 0,\n",
       " 781: 0,\n",
       " 782: 0.029940119760479042,\n",
       " 783: 0.0064516129032258064,\n",
       " 784: 0,\n",
       " 785: 0.0011361484567316796,\n",
       " 786: 0.0086728777454361285,\n",
       " 787: 0.0015156225670600681,\n",
       " 788: 0.0075585789871504159,\n",
       " 789: 0.0071315372424722665,\n",
       " 790: 0.011167011959107392,\n",
       " 791: 0.013298655265868382,\n",
       " 792: 0.0013057879951362391,\n",
       " 793: 0,\n",
       " 794: 0.0029510879013926374,\n",
       " 795: 0,\n",
       " 796: 0.0011908795055796811,\n",
       " 797: 0.018311291963377416,\n",
       " 798: 0.027646874018221804,\n",
       " 799: 0.00051334702258726901,\n",
       " 800: 0.0014347926703553321,\n",
       " 801: 0,\n",
       " 802: 0,\n",
       " 803: 0.00099492587802208735,\n",
       " 804: 0.0035018603633180127,\n",
       " 805: 0,\n",
       " 806: 0.0065843621399176953,\n",
       " 807: 0.0010710486469301954,\n",
       " 808: 0.00052557813594954455,\n",
       " 809: 0.056800941333867677,\n",
       " 810: 0,\n",
       " 811: 0.033898305084745763,\n",
       " 812: 0.00593226732353643,\n",
       " 813: 0.013449167883095421,\n",
       " 814: 0.0076680198466396029,\n",
       " 815: 0.00042544139544777704,\n",
       " 816: 0.0063616610360261883,\n",
       " 817: 0.0025494901019796042,\n",
       " 818: 0.0034336753561766522,\n",
       " 819: 0.0015077271013946476,\n",
       " 820: 0.00094803778498683009,\n",
       " 821: 0.0028490028490028491,\n",
       " 822: 0.0078236130867709811,\n",
       " 823: 0.0029484029484029483,\n",
       " 824: 0.038461538461538464,\n",
       " 825: 0.011111111111111112,\n",
       " 826: 0.010813999213527331,\n",
       " 827: 0,\n",
       " 828: 0.0086058519793459545,\n",
       " 829: 0,\n",
       " 830: 0.055727554179566562,\n",
       " 831: 0,\n",
       " 832: 0.00072997140945312976,\n",
       " 833: 0.0038726740341928781,\n",
       " 834: 0.0019083969465648854,\n",
       " 835: 0.016920473773265651,\n",
       " 836: 0.012150668286755772,\n",
       " 837: 0.012725344644750796,\n",
       " 838: 0,\n",
       " 839: 0.0011425172942686325,\n",
       " 840: 0.0026041666666666665,\n",
       " 841: 0,\n",
       " 842: 0,\n",
       " 843: 0.00016903313049357674,\n",
       " 844: 0,\n",
       " 845: 0.0023584905660377358,\n",
       " 846: 0.00099833610648918472,\n",
       " 847: 0.0025802418706276473,\n",
       " 848: 0.00085496473270477592,\n",
       " 849: 0.0051615435066341038,\n",
       " 850: 0.0074424898511502033,\n",
       " 851: 0.0021266013359382049,\n",
       " 852: 0.0013440860215053765,\n",
       " 853: 0.046092184368737472,\n",
       " 854: 0.0050213873907383301,\n",
       " 855: 0.010345768045699703,\n",
       " 856: 0.0072774183161716747,\n",
       " 857: 0.0033715388094245468,\n",
       " 858: 0.0041405871199150712,\n",
       " 859: 0.00065767839526471557,\n",
       " 860: 0.001254180602006689,\n",
       " 861: 0,\n",
       " 862: 0.11910307647475127,\n",
       " 863: 0.023809523809523808,\n",
       " 864: 0.00069657286152131513,\n",
       " 865: 0,\n",
       " 866: 0,\n",
       " 867: 0.015904572564612324,\n",
       " 868: 0,\n",
       " 869: 0.010810810810810811,\n",
       " 870: 0.0011619205167592264,\n",
       " 871: 0.00061167986607430305,\n",
       " 872: 0,\n",
       " 873: 0.086007702182284984,\n",
       " 874: 0,\n",
       " 875: 0.00057355893318038426,\n",
       " 876: 0.00067750677506775068,\n",
       " 877: 0,\n",
       " 878: 0.0014940810133728521,\n",
       " 879: 0.0001658649859014762,\n",
       " 880: 0.0013034719753525299,\n",
       " 881: 0.0012240690632650431,\n",
       " 882: 0.013256006628003313,\n",
       " 883: 0.21450113177542035,\n",
       " 884: 6.7132116004296454e-05,\n",
       " 885: 0.0039381780353692974,\n",
       " 886: 0,\n",
       " 887: 0.0067455042378238997,\n",
       " 888: 0.003244615753058296,\n",
       " 889: 0.0,\n",
       " 890: 0.0088979591836734692,\n",
       " 891: 0.0010296256934189127,\n",
       " 892: 0,\n",
       " 893: 0.00013376136971642589,\n",
       " 894: 0,\n",
       " 895: 0.0081845238095238099,\n",
       " 896: 0.0031702385745679186,\n",
       " 897: 0,\n",
       " 898: 0.009831327880620265,\n",
       " 899: 0.012082444918265814,\n",
       " 900: 0.01507537688442211,\n",
       " 901: 0.013902681231380337,\n",
       " 902: 0,\n",
       " 903: 0.015789853503644369,\n",
       " 904: 0.019166666666666665,\n",
       " 905: 0.00077493378364311405,\n",
       " 906: 0.0034246575342465752,\n",
       " 907: 0.0037821482602118004,\n",
       " 908: 0,\n",
       " 909: 0,\n",
       " 910: 0.00057110222729868647,\n",
       " 911: 0.0068995221618434613,\n",
       " 912: 0.016393442622950821,\n",
       " 913: 0.00076757143046199861,\n",
       " 914: 0.00016628559551028893,\n",
       " 915: 0.0011329305135951663,\n",
       " 916: 0.0022938377888536473,\n",
       " 917: 0.0046193296769414596,\n",
       " 918: 0.0011962931045541945,\n",
       " 919: 0,\n",
       " 920: 0.0072360582371915954,\n",
       " 921: 0.012367230527143981,\n",
       " 922: 0.0025720620842572062,\n",
       " 923: 0.0049774223691886306,\n",
       " 924: 0.00054392167527875983,\n",
       " 925: 0.02188707579386753,\n",
       " 926: 7.5642965204236e-05,\n",
       " 927: 0.018181818181818181,\n",
       " 928: 0.00071566062879423523,\n",
       " 929: 0,\n",
       " 930: 0.0011923688394276629,\n",
       " 931: 0.0015304560759106215,\n",
       " 932: 0,\n",
       " 933: 0.00073571787671820779,\n",
       " 934: 0.0051304732419283506,\n",
       " 935: 0.00065772645887382617,\n",
       " 936: 0.0046139583018908609,\n",
       " 937: 0.012616370758508419,\n",
       " 938: 0.0022435897435897434,\n",
       " 939: 0,\n",
       " 940: 0,\n",
       " 941: 0,\n",
       " 942: 0.0040415704387990765,\n",
       " 943: 0.0014336917562724014,\n",
       " 944: 0,\n",
       " 945: 0,\n",
       " 946: 0.0028429282160625444,\n",
       " 947: 0.0,\n",
       " 948: 0.00010385294423096895,\n",
       " 949: 0.0052193676482146381,\n",
       " 950: 0.12987012987012986,\n",
       " 951: 0.0011758833877097735,\n",
       " 952: 0.001726689689195856,\n",
       " 953: 0.006889763779527559,\n",
       " 954: 0.00035762820971318218,\n",
       " 955: 0.0028198745090976234,\n",
       " 956: 0.0006780201810712719,\n",
       " 957: 0.014378851478074484,\n",
       " 958: 0,\n",
       " 959: 0.034278155706727133,\n",
       " 960: 0.0013546709692616545,\n",
       " 961: 0,\n",
       " 962: 0.00077076532462821913,\n",
       " 963: 0.003071304059101851,\n",
       " 964: 0.0067901234567901234,\n",
       " 965: 0.081318675651088579,\n",
       " 966: 0.00063191153238546598,\n",
       " 967: 0.0053475935828877002,\n",
       " 968: 0.0042390167346308197,\n",
       " 969: 0.00099009900990099011,\n",
       " 970: 0,\n",
       " 971: 0.001754449763814313,\n",
       " 972: 0.0023927767033287846,\n",
       " 973: 0,\n",
       " 974: 0,\n",
       " 975: 0.0,\n",
       " 976: 0.0002407028523288001,\n",
       " 977: 0.0068402411630448905,\n",
       " 978: 0.015167699209570605,\n",
       " 979: 0.0010744985673352436,\n",
       " 980: 0.0071504209928198769,\n",
       " 981: 0.010242085661080074,\n",
       " 982: 0.0009225092250922509,\n",
       " 983: 0.0012162479887478652,\n",
       " 984: 0.0022016645919822006,\n",
       " 985: 0,\n",
       " 986: 0.0,\n",
       " 987: 0,\n",
       " 988: 0.0031438302331674088,\n",
       " 989: 0.0038895371450797353,\n",
       " 990: 0.0025616698292220113,\n",
       " 991: 0,\n",
       " 992: 0.013598514191861387,\n",
       " 993: 0.00041707215348255251,\n",
       " 994: 0,\n",
       " 995: 0,\n",
       " 996: 0,\n",
       " 997: 0.0050193063638786055,\n",
       " 998: 0.026595744680851064,\n",
       " 999: 0,\n",
       " ...}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['Username'] = train['Username'].map(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answers</th>\n",
       "      <th>ID</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Username</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>366953</td>\n",
       "      <td>-0.078641</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>0.043912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>71864</td>\n",
       "      <td>0.618514</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029499</td>\n",
       "      <td>-0.332464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>141692</td>\n",
       "      <td>-0.252986</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>-0.104724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>316833</td>\n",
       "      <td>-0.286465</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-0.137322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>440445</td>\n",
       "      <td>-0.121876</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>0.340861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3514</td>\n",
       "      <td>-0.167070</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>-0.337689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>331420</td>\n",
       "      <td>-0.255498</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020569</td>\n",
       "      <td>-0.285809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>406540</td>\n",
       "      <td>-0.258787</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.347470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>227379</td>\n",
       "      <td>0.035248</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007295</td>\n",
       "      <td>-0.311106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>331687</td>\n",
       "      <td>-0.280959</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.305671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>32784</td>\n",
       "      <td>-0.285098</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.350733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>470377</td>\n",
       "      <td>-0.260376</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>-0.022618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>338103</td>\n",
       "      <td>-0.239387</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>-0.331265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.0</td>\n",
       "      <td>29883</td>\n",
       "      <td>-0.241752</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>1.642512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.0</td>\n",
       "      <td>218228</td>\n",
       "      <td>-0.279666</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>0.086861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>70945</td>\n",
       "      <td>10.354517</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333315</td>\n",
       "      <td>-0.329511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>14328</td>\n",
       "      <td>-0.228486</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>-0.220613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>259947</td>\n",
       "      <td>-0.091095</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>-0.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.0</td>\n",
       "      <td>346378</td>\n",
       "      <td>-0.089358</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.695039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>384621</td>\n",
       "      <td>-0.287019</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.353944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>425418</td>\n",
       "      <td>-0.274197</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>-0.192092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.0</td>\n",
       "      <td>131224</td>\n",
       "      <td>-0.112564</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>-0.128638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>365408</td>\n",
       "      <td>-0.266363</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.230088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>218626</td>\n",
       "      <td>-0.281365</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>-0.314244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.0</td>\n",
       "      <td>331722</td>\n",
       "      <td>-0.250916</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>-0.241266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>310969</td>\n",
       "      <td>-0.273642</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>-0.288712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.0</td>\n",
       "      <td>307391</td>\n",
       "      <td>0.778594</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>-0.310995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.0</td>\n",
       "      <td>14072</td>\n",
       "      <td>0.399752</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022152</td>\n",
       "      <td>-0.211547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>238694</td>\n",
       "      <td>-0.283398</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.357032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.0</td>\n",
       "      <td>213841</td>\n",
       "      <td>-0.242343</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>-0.330339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141418</th>\n",
       "      <td>3.0</td>\n",
       "      <td>158414</td>\n",
       "      <td>-0.190498</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>-0.337429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141419</th>\n",
       "      <td>4.0</td>\n",
       "      <td>29710</td>\n",
       "      <td>2.548162</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076296</td>\n",
       "      <td>0.054065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141420</th>\n",
       "      <td>3.0</td>\n",
       "      <td>370802</td>\n",
       "      <td>-0.284802</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.214190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141421</th>\n",
       "      <td>1.0</td>\n",
       "      <td>264407</td>\n",
       "      <td>-0.256422</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.351943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141422</th>\n",
       "      <td>1.0</td>\n",
       "      <td>159508</td>\n",
       "      <td>-0.258492</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.273024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141423</th>\n",
       "      <td>10.0</td>\n",
       "      <td>18508</td>\n",
       "      <td>-0.287241</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.436295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141424</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9046</td>\n",
       "      <td>0.197028</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015876</td>\n",
       "      <td>0.557373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141425</th>\n",
       "      <td>10.0</td>\n",
       "      <td>358118</td>\n",
       "      <td>0.488993</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077743</td>\n",
       "      <td>0.359266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141426</th>\n",
       "      <td>3.0</td>\n",
       "      <td>470852</td>\n",
       "      <td>-0.137286</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.448191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141427</th>\n",
       "      <td>3.0</td>\n",
       "      <td>106824</td>\n",
       "      <td>-0.286391</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.264637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141428</th>\n",
       "      <td>3.0</td>\n",
       "      <td>371009</td>\n",
       "      <td>0.236383</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022218</td>\n",
       "      <td>-0.340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141429</th>\n",
       "      <td>9.0</td>\n",
       "      <td>434645</td>\n",
       "      <td>-0.119881</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>-0.194933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141430</th>\n",
       "      <td>20.0</td>\n",
       "      <td>461727</td>\n",
       "      <td>-0.264182</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>3.711451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141431</th>\n",
       "      <td>4.0</td>\n",
       "      <td>208029</td>\n",
       "      <td>-0.287241</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.798144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141432</th>\n",
       "      <td>3.0</td>\n",
       "      <td>133474</td>\n",
       "      <td>-0.285172</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>-0.298211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141433</th>\n",
       "      <td>1.0</td>\n",
       "      <td>404689</td>\n",
       "      <td>-0.240828</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010403</td>\n",
       "      <td>-0.335206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141434</th>\n",
       "      <td>1.0</td>\n",
       "      <td>113320</td>\n",
       "      <td>-0.286317</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.273049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141435</th>\n",
       "      <td>1.0</td>\n",
       "      <td>403339</td>\n",
       "      <td>0.056052</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>-0.253508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141436</th>\n",
       "      <td>3.0</td>\n",
       "      <td>65118</td>\n",
       "      <td>-0.224310</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.046234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141437</th>\n",
       "      <td>1.0</td>\n",
       "      <td>142461</td>\n",
       "      <td>-0.271610</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.363913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141438</th>\n",
       "      <td>2.0</td>\n",
       "      <td>338255</td>\n",
       "      <td>-0.285726</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>1.107916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141439</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15418</td>\n",
       "      <td>-0.282252</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>-0.358712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141440</th>\n",
       "      <td>2.0</td>\n",
       "      <td>267690</td>\n",
       "      <td>-0.113968</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>-0.113506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141441</th>\n",
       "      <td>2.0</td>\n",
       "      <td>108226</td>\n",
       "      <td>-0.244745</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>-0.280411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141442</th>\n",
       "      <td>3.0</td>\n",
       "      <td>166359</td>\n",
       "      <td>-0.092499</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>-0.305276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141443</th>\n",
       "      <td>4.0</td>\n",
       "      <td>47187</td>\n",
       "      <td>-0.114264</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>-0.335688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141444</th>\n",
       "      <td>3.0</td>\n",
       "      <td>329126</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014699</td>\n",
       "      <td>-0.131516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141445</th>\n",
       "      <td>5.0</td>\n",
       "      <td>282334</td>\n",
       "      <td>-0.271166</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>0.338490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141446</th>\n",
       "      <td>3.0</td>\n",
       "      <td>386629</td>\n",
       "      <td>-0.280737</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>-0.240278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141447</th>\n",
       "      <td>2.0</td>\n",
       "      <td>107271</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>-0.208261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141448 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Answers      ID  Reputation  Tag  Upvotes  Username     Views\n",
       "0           3.0  366953   -0.078641    0      NaN  0.006919  0.043912\n",
       "1           6.0   71864    0.618514    1      NaN  0.029499 -0.332464\n",
       "2           1.0  141692   -0.252986    3      NaN  0.002964 -0.104724\n",
       "3           6.0  316833   -0.286465    3      NaN  0.000216 -0.137322\n",
       "4          10.0  440445   -0.121876    3      NaN  0.017881  0.340861\n",
       "5           1.0    3514   -0.167070    1      NaN  0.006969 -0.337689\n",
       "6           1.0  331420   -0.255498    9      NaN  0.020569 -0.285809\n",
       "7           4.0  406540   -0.258787    1      NaN  0.000424  0.347470\n",
       "8           2.0  227379    0.035248    8      NaN  0.007295 -0.311106\n",
       "9           4.0  331687   -0.280959    6      NaN  0.011371 -0.305671\n",
       "10          2.0   32784   -0.285098    6      NaN  0.011371 -0.350733\n",
       "11          2.0  470377   -0.260376    8      NaN  0.000429 -0.022618\n",
       "12          3.0  338103   -0.239387    5      NaN  0.005820 -0.331265\n",
       "13          7.0   29883   -0.241752    6      NaN  0.011371  1.642512\n",
       "14          8.0  218228   -0.279666    1      NaN  0.011371  0.086861\n",
       "15          1.0   70945   10.354517    1      NaN  0.333315 -0.329511\n",
       "16          3.0   14328   -0.228486    1      NaN  0.001648 -0.220613\n",
       "17          3.0  259947   -0.091095    0      NaN  0.013058 -0.148500\n",
       "18          8.0  346378   -0.089358    4      NaN  0.007072  0.695039\n",
       "19          3.0  384621   -0.287019    4      NaN  0.011371 -0.353944\n",
       "20          3.0  425418   -0.274197    3      NaN  0.001561 -0.192092\n",
       "21          4.0  131224   -0.112564    5      NaN  0.006178 -0.128638\n",
       "22          2.0  365408   -0.266363    0      NaN  0.011371 -0.230088\n",
       "23          4.0  218626   -0.281365    8      NaN  0.001227 -0.314244\n",
       "24          7.0  331722   -0.250916    3      NaN  0.001728 -0.241266\n",
       "25          5.0  310969   -0.273642    6      NaN  0.002215 -0.288712\n",
       "26          4.0  307391    0.778594    6      NaN  0.019455 -0.310995\n",
       "27          4.0   14072    0.399752    4      NaN  0.022152 -0.211547\n",
       "28          1.0  238694   -0.283398    4      NaN  0.011371 -0.357032\n",
       "29          2.0  213841   -0.242343    6      NaN  0.002527 -0.330339\n",
       "...         ...     ...         ...  ...      ...       ...       ...\n",
       "141418      3.0  158414   -0.190498    5      NaN  0.002842 -0.337429\n",
       "141419      4.0   29710    2.548162    0      NaN  0.076296  0.054065\n",
       "141420      3.0  370802   -0.284802    3      NaN  0.011371 -0.214190\n",
       "141421      1.0  264407   -0.256422    6      NaN  0.011371 -0.351943\n",
       "141422      1.0  159508   -0.258492    6      NaN  0.011371 -0.273024\n",
       "141423     10.0   18508   -0.287241    3      NaN  0.002206  0.436295\n",
       "141424      8.0    9046    0.197028    4      NaN  0.015876  0.557373\n",
       "141425     10.0  358118    0.488993    2      NaN  0.077743  0.359266\n",
       "141426      3.0  470852   -0.137286    4      NaN  0.006274  0.448191\n",
       "141427      3.0  106824   -0.286391    4      NaN  0.011371 -0.264637\n",
       "141428      3.0  371009    0.236383    3      NaN  0.022218 -0.340900\n",
       "141429      9.0  434645   -0.119881    6      NaN  0.006052 -0.194933\n",
       "141430     20.0  461727   -0.264182    4      NaN  0.011371  3.711451\n",
       "141431      4.0  208029   -0.287241    4      NaN  0.021100  0.798144\n",
       "141432      3.0  133474   -0.285172    0      NaN  0.000545 -0.298211\n",
       "141433      1.0  404689   -0.240828    1      NaN  0.010403 -0.335206\n",
       "141434      1.0  113320   -0.286317    8      NaN  0.011371 -0.273049\n",
       "141435      1.0  403339    0.056052    0      NaN  0.011698 -0.253508\n",
       "141436      3.0   65118   -0.224310    1      NaN  0.002722  0.046234\n",
       "141437      1.0  142461   -0.271610    0      NaN  0.011371 -0.363913\n",
       "141438      2.0  338255   -0.285726    8      NaN  0.011371  1.107916\n",
       "141439      1.0   15418   -0.282252    5      NaN  0.004435 -0.358712\n",
       "141440      2.0  267690   -0.113968    0      NaN  0.005344 -0.113506\n",
       "141441      2.0  108226   -0.244745    1      NaN  0.011371 -0.280411\n",
       "141442      3.0  166359   -0.092499    0      NaN  0.007176 -0.305276\n",
       "141443      4.0   47187   -0.114264    4      NaN  0.004871 -0.335688\n",
       "141444      3.0  329126    0.000327    4      NaN  0.014699 -0.131516\n",
       "141445      5.0  282334   -0.271166    6      NaN  0.011371  0.338490\n",
       "141446      3.0  386629   -0.280737    5      NaN  0.001153 -0.240278\n",
       "141447      2.0  107271   -0.263295    0      NaN  0.000634 -0.208261\n",
       "\n",
       "[141448 rows x 7 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train[['Tag','Views','new','Reputation']]\n",
    "y = train[['Upvotes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_v = test['Views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['Reputation'] = (test['Reputation'] - avr) / sr\n",
    "test['Views'] = (test['Views'] - avv) / sv\n",
    "test['new'] = (test['new'] - nr) / nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Username'] = test['Username'].map(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.replace({'Username': {0.0: test['Username'].mean()}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = test[['Tag','Views','new','Reputation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_size = 0.1\n",
    "seed = 0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=val_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_squared_error, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GradientBoostingRegressor' object has no attribute 'GradientBoostingRegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-1153b0057876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ensemble = ensemble.GradientBoostingRegressor(n_estimators = 75,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                               \u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                               min_samples_split = 2)\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgbr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GradientBoostingRegressor' object has no attribute 'GradientBoostingRegressor'"
     ]
    }
   ],
   "source": [
    "ensemble = ensemble.GradientBoostingRegressor(n_estimators = 75,\n",
    "                                              max_depth = 5, \n",
    "                                              min_samples_split = 2)\n",
    "\n",
    "gbr = ensemble.fit(x_train, y_train)\n",
    "print(ensemble.score(x_val, y_val))\n",
    "#print(np.sqrt(-cross_val_score(gbr, x_train, y_train, scoring = scorer, cv = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.279602740204\n",
      "[ 2223.07112334  3522.35419409  3075.93546284  4190.4107827   2954.84706548]\n"
     ]
    }
   ],
   "source": [
    "ols_simple = linear_model.LinearRegression()\n",
    "\n",
    "lr = ols_simple.fit(x_train, y_train)\n",
    "print(ols_simple.score(x_val, y_val))\n",
    "print(np.sqrt(-cross_val_score(lr, x_train, y_train, scoring = scorer, cv = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934377121614\n",
      "[  863.16333954  1281.75743713   986.74164584  1638.30873999   959.31992945]\n"
     ]
    }
   ],
   "source": [
    "ridgecv = linear_model.RidgeCV(alphas = [0.001, 0.01, 0.1, 0.5, 0.75, 1, 1.2, 1.5, 2.5, 5])\n",
    "\n",
    "ridge = ridgecv.fit(x_train, y_train)\n",
    "print(ridgecv.score(x_val, y_val))\n",
    "print(np.sqrt(-cross_val_score(ridge, x_train, y_train, scoring = scorer, cv = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911476821667\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(\n",
    "                             learning_rate=0.05, max_depth=4, \n",
    "                            n_estimators=150, seed = 1894,\n",
    "                              nthread = -1)\n",
    "\n",
    "xg = model_xgb.fit(x_train, y_train)\n",
    "print(model_xgb.score(x_val, y_val))\n",
    "#print(np.sqrt(-cross_val_score(xg, x_train, y_train, scoring = scorer, cv = 5)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.304120664324\n",
      "[ 2132.01557516  3438.04028563  2997.03022946  4134.60272928  2891.83498791]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "\n",
    "lass = lasso.fit(x_train, y_train)\n",
    "print(lasso.score(x_val, y_val))\n",
    "print(np.sqrt(-cross_val_score(lass, x_train, y_train, scoring = scorer, cv = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.098273073253\n",
      "[ 2457.38492847  3838.61704482  3287.26560416  4593.70392905  3214.23088685]\n"
     ]
    }
   ],
   "source": [
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "\n",
    "elas = ENet.fit(x_train, y_train)\n",
    "print(elas.score(x_val, y_val))\n",
    "print(np.sqrt(-cross_val_score(elas, x_train, y_train, scoring = scorer, cv = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918982713365\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=50, random_state=47, n_jobs=-1)\n",
    "\n",
    "rand = rf.fit(x_train,y_train)\n",
    "print(rf.score(x_val,y_val))\n",
    "#print(np.sqrt(-cross_val_score(rand, x_train, y_train, scoring = scorer, cv = 5)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.895333403012\n"
     ]
    }
   ],
   "source": [
    "xt = ExtraTreesRegressor(n_estimators=100)\n",
    "\n",
    "xt = xt.fit(x_train,y_train)\n",
    "print(xt.score(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000148512766F0, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000148512766F0, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 if __name__ == '__main__':\n      2     from ipykernel import kernelapp as app\n----> 3     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-09-01T15:11:07.764144', 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'session': 'E5BC9B2FE2CD4C0BB824F51A0ECDFB72', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'E5BC9B2FE2CD4C0BB824F51A0ECDFB72']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-09-01T15:11:07.764144', 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'session': 'E5BC9B2FE2CD4C0BB824F51A0ECDFB72', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'E5BC9B2FE2CD4C0BB824F51A0ECDFB72'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-09-01T15:11:07.764144', 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'session': 'E5BC9B2FE2CD4C0BB824F51A0ECDFB72', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-297-2079d77a5a76>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 14800029e48, executio..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000014862638660, file \"<ipython-input-297-2079d77a5a76>\", line 2>\n        result = <ExecutionResult object at 14800029e48, executio..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000014862638660, file \"<ipython-input-297-2079d77a5a76>\", line 2>, result=<ExecutionResult object at 14800029e48, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000014862638660, file \"<ipython-input-297-2079d77a5a76>\", line 2>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingRegressor': <class 'sklearn.ensemble.bagging.BaggingRegressor'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'BayesianRidge': <class 'sklearn.linear_model.bayes.BayesianRidge'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import pandas as pd\\nimport matplotlib.pyplot as ...rror\\nimport xgboost as xgb\\nimport lightgbm as lgb', 'train = pd.read_csv(\"C:/Users/L3IN/Downloads/eni..._csv(\"C:/Users/L3IN/Downloads/enigma18/test.csv\")', 'train.describe()', \"train['Reputation'].idxmax()\", 'train[160728:160729]', \"train['Views'].idxmax()\", 'train[98585:98586]', \"from sklearn.preprocessing import LabelEncoder\\n\\n...['Views'] = lb_make.fit_transform(train['Views'])\", \"d = {}\\nmax_user = train['Username'].max()\\nval = ...ge(val):\\n    d[int(train.ix[i]['Username'])] += 1\", \"train['uv'] = train['Upvotes']/train['Views']\", \"v = {}\\nmax_user = train['Username'].max()\\nval = ... x1 = int(temp['Username'])\\n    v[x1] += uv/d[x1]\", \"train['upview'] = v[train['Username'].astype(int)]\", \"train['upview'] = v[train['Username']]\", \"usr = np.array(train['Username'])\", 'usr', \"train['upview'] = v[usr]\", \"train.replace({'Username': v})\", \"train['Username'].map(v)\", 'train', ...], ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingRegressor': <class 'sklearn.ensemble.bagging.BaggingRegressor'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'BayesianRidge': <class 'sklearn.linear_model.bayes.BayesianRidge'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import pandas as pd\\nimport matplotlib.pyplot as ...rror\\nimport xgboost as xgb\\nimport lightgbm as lgb', 'train = pd.read_csv(\"C:/Users/L3IN/Downloads/eni..._csv(\"C:/Users/L3IN/Downloads/enigma18/test.csv\")', 'train.describe()', \"train['Reputation'].idxmax()\", 'train[160728:160729]', \"train['Views'].idxmax()\", 'train[98585:98586]', \"from sklearn.preprocessing import LabelEncoder\\n\\n...['Views'] = lb_make.fit_transform(train['Views'])\", \"d = {}\\nmax_user = train['Username'].max()\\nval = ...ge(val):\\n    d[int(train.ix[i]['Username'])] += 1\", \"train['uv'] = train['Upvotes']/train['Views']\", \"v = {}\\nmax_user = train['Username'].max()\\nval = ... x1 = int(temp['Username'])\\n    v[x1] += uv/d[x1]\", \"train['upview'] = v[train['Username'].astype(int)]\", \"train['upview'] = v[train['Username']]\", \"usr = np.array(train['Username'])\", 'usr', \"train['upview'] = v[usr]\", \"train.replace({'Username': v})\", \"train['Username'].map(v)\", 'train', ...], ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\L3IN\\Downloads\\enigma18\\<ipython-input-297-2079d77a5a76> in <module>()\n      1 bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\n----> 2 bg.fit(x_train,y_train)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py in fit(self=BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), X=        Tag     Views       new  Reputation\n3241... -0.085310   -0.272349\n\n[297040 rows x 4 columns], y=        Upvotes\n324119      1.0\n146493    179.0\n...  26.0\n305711     16.0\n\n[297040 rows x 1 columns], sample_weight=None)\n    242         Returns\n    243         -------\n    244         self : object\n    245             Returns self.\n    246         \"\"\"\n--> 247         return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n        self._fit = <bound method BaseBagging._fit of BaggingRegress... random_state=None, verbose=0, warm_start=False)>\n        X =         Tag     Views       new  Reputation\n3241... -0.085310   -0.272349\n\n[297040 rows x 4 columns]\n        y =         Upvotes\n324119      1.0\n146493    179.0\n...  26.0\n305711     16.0\n\n[297040 rows x 1 columns]\n        self.max_samples = 1.0\n        sample_weight = None\n    248 \n    249     def _fit(self, X, y, max_samples=None, max_depth=None, sample_weight=None):\n    250         \"\"\"Build a Bagging ensemble of estimators from the training\n    251            set (X, y).\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py in _fit(self=BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), X=array([[ 3.        , -0.35095498, -0.08864828, -...       ,  0.04614738, -0.08530985, -0.27234893]]), y=array([   1.,  179.,    9., ...,    6.,   26.,   16.]), max_samples=297040, max_depth=None, sample_weight=None)\n    370                 y,\n    371                 sample_weight,\n    372                 seeds[starts[i]:starts[i + 1]],\n    373                 total_n_estimators,\n    374                 verbose=self.verbose)\n--> 375             for i in range(n_jobs))\n        n_jobs = 4\n    376 \n    377         # Reduce\n    378         self.estimators_ += list(itertools.chain.from_iterable(\n    379             t[0] for t in all_results))\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseBagging._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Sat Sep  1 15:11:41 2018\nPID: 14080                Python 3.6.2: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_estimators>, (3, BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), None, array([1848545992, 1844787845,  475608774]), 10), {'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_estimators>\n        args = (3, BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), None, array([1848545992, 1844787845,  475608774]), 10)\n        kwargs = {'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py in _parallel_build_estimators(n_estimators=3, ensemble=BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), X=memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), y=memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), sample_weight=None, seeds=array([1848545992, 1844787845,  475608774]), total_n_estimators=10, verbose=0)\n    107                 curr_sample_weight *= sample_counts\n    108             else:\n    109                 not_indices_mask = ~indices_to_mask(indices, n_samples)\n    110                 curr_sample_weight[not_indices_mask] = 0\n    111 \n--> 112             estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n        estimator.fit = <bound method _BaseRidgeCV.fit of RidgeCV(alphas...=False, scoring=None,\n    store_cv_values=False)>\n        X = memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]])\n        features = array([0, 1, 2, 3])\n        y = memmap([   1.,  179.,    9., ...,    6.,   26.,   16.])\n        sample_weight = None\n        curr_sample_weight = array([ 0.,  3.,  2., ...,  0.,  1.,  0.])\n    113 \n    114         # Draw samples, using a mask, and then fit\n    115         else:\n    116             estimator.fit((X[indices])[:, features], y[indices])\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in fit(self=RidgeCV(alphas=[0.001, 0.01, 0.1, 0.5, 0.75, 1, ...e=False, scoring=None,\n    store_cv_values=False), X=array([[ 3.        , -0.35095498, -0.08864828, -...       ,  0.04614738, -0.08530985, -0.27234893]]), y=memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), sample_weight=array([ 0.,  3.,  2., ...,  0.,  1.,  0.]))\n   1109                                   fit_intercept=self.fit_intercept,\n   1110                                   normalize=self.normalize,\n   1111                                   scoring=self.scoring,\n   1112                                   gcv_mode=self.gcv_mode,\n   1113                                   store_cv_values=self.store_cv_values)\n-> 1114             estimator.fit(X, y, sample_weight=sample_weight)\n        estimator.fit = <bound method _RidgeGCV.fit of _RidgeGCV(alphas=...False,\n     scoring=None, store_cv_values=False)>\n        X = array([[ 3.        , -0.35095498, -0.08864828, -...       ,  0.04614738, -0.08530985, -0.27234893]])\n        y = memmap([   1.,  179.,    9., ...,    6.,   26.,   16.])\n        sample_weight = array([ 0.,  3.,  2., ...,  0.,  1.,  0.])\n   1115             self.alpha_ = estimator.alpha_\n   1116             if self.store_cv_values:\n   1117                 self.cv_values_ = estimator.cv_values_\n   1118         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in fit(self=_RidgeGCV(alphas=array([  1.00000e-03,   1.00000...=False,\n     scoring=None, store_cv_values=False), X=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), y=array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ]), sample_weight=array([ 0.,  3.,  2., ...,  0.,  1.,  0.]))\n   1024         if sample_weight is not None:\n   1025             X, y = _rescale_data(X, y, sample_weight)\n   1026 \n   1027         centered_kernel = not sparse.issparse(X) and self.fit_intercept\n   1028 \n-> 1029         v, Q, QT_y = _pre_compute(X, y, centered_kernel)\n        v = undefined\n        Q = undefined\n        QT_y = undefined\n        _pre_compute = <bound method _RidgeGCV._pre_compute of _RidgeGC...False,\n     scoring=None, store_cv_values=False)>\n        X = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        y = array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ])\n        centered_kernel = True\n   1030         n_y = 1 if len(y.shape) == 1 else y.shape[1]\n   1031         cv_values = np.zeros((n_samples * n_y, len(self.alphas)))\n   1032         C = []\n   1033 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in _pre_compute(self=_RidgeGCV(alphas=array([  1.00000e-03,   1.00000...=False,\n     scoring=None, store_cv_values=False), X=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), y=array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ]), centered_kernel=True)\n    880         self.gcv_mode = gcv_mode\n    881         self.store_cv_values = store_cv_values\n    882 \n    883     def _pre_compute(self, X, y, centered_kernel=True):\n    884         # even if X is very sparse, K is usually very dense\n--> 885         K = safe_sparse_dot(X, X.T, dense_output=True)\n        K = undefined\n        X = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        X.T = array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]])\n    886         # the following emulates an additional constant regressor\n    887         # corresponding to fit_intercept=True\n    888         # but this is done only when the features have been centered\n    889         if centered_kernel:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py in safe_sparse_dot(a=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), b=array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]]), dense_output=True)\n    135         ret = a * b\n    136         if dense_output and hasattr(ret, \"toarray\"):\n    137             ret = ret.toarray()\n    138         return ret\n    139     else:\n--> 140         return np.dot(a, b)\n        a = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        b = array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]])\n    141 \n    142 \n    143 def randomized_range_finder(A, size, n_iter,\n    144                             power_iteration_normalizer='auto',\n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py\", line 112, in _parallel_build_estimators\n    estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\", line 1114, in fit\n    estimator.fit(X, y, sample_weight=sample_weight)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\", line 1029, in fit\n    v, Q, QT_y = _pre_compute(X, y, centered_kernel)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\", line 885, in _pre_compute\n    K = safe_sparse_dot(X, X.T, dense_output=True)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\", line 140, in safe_sparse_dot\n    return np.dot(a, b)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Sat Sep  1 15:11:41 2018\nPID: 14080                Python 3.6.2: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_estimators>, (3, BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), None, array([1848545992, 1844787845,  475608774]), 10), {'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_estimators>\n        args = (3, BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), None, array([1848545992, 1844787845,  475608774]), 10)\n        kwargs = {'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py in _parallel_build_estimators(n_estimators=3, ensemble=BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), X=memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), y=memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), sample_weight=None, seeds=array([1848545992, 1844787845,  475608774]), total_n_estimators=10, verbose=0)\n    107                 curr_sample_weight *= sample_counts\n    108             else:\n    109                 not_indices_mask = ~indices_to_mask(indices, n_samples)\n    110                 curr_sample_weight[not_indices_mask] = 0\n    111 \n--> 112             estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n        estimator.fit = <bound method _BaseRidgeCV.fit of RidgeCV(alphas...=False, scoring=None,\n    store_cv_values=False)>\n        X = memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]])\n        features = array([0, 1, 2, 3])\n        y = memmap([   1.,  179.,    9., ...,    6.,   26.,   16.])\n        sample_weight = None\n        curr_sample_weight = array([ 0.,  3.,  2., ...,  0.,  1.,  0.])\n    113 \n    114         # Draw samples, using a mask, and then fit\n    115         else:\n    116             estimator.fit((X[indices])[:, features], y[indices])\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in fit(self=RidgeCV(alphas=[0.001, 0.01, 0.1, 0.5, 0.75, 1, ...e=False, scoring=None,\n    store_cv_values=False), X=array([[ 3.        , -0.35095498, -0.08864828, -...       ,  0.04614738, -0.08530985, -0.27234893]]), y=memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), sample_weight=array([ 0.,  3.,  2., ...,  0.,  1.,  0.]))\n   1109                                   fit_intercept=self.fit_intercept,\n   1110                                   normalize=self.normalize,\n   1111                                   scoring=self.scoring,\n   1112                                   gcv_mode=self.gcv_mode,\n   1113                                   store_cv_values=self.store_cv_values)\n-> 1114             estimator.fit(X, y, sample_weight=sample_weight)\n        estimator.fit = <bound method _RidgeGCV.fit of _RidgeGCV(alphas=...False,\n     scoring=None, store_cv_values=False)>\n        X = array([[ 3.        , -0.35095498, -0.08864828, -...       ,  0.04614738, -0.08530985, -0.27234893]])\n        y = memmap([   1.,  179.,    9., ...,    6.,   26.,   16.])\n        sample_weight = array([ 0.,  3.,  2., ...,  0.,  1.,  0.])\n   1115             self.alpha_ = estimator.alpha_\n   1116             if self.store_cv_values:\n   1117                 self.cv_values_ = estimator.cv_values_\n   1118         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in fit(self=_RidgeGCV(alphas=array([  1.00000e-03,   1.00000...=False,\n     scoring=None, store_cv_values=False), X=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), y=array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ]), sample_weight=array([ 0.,  3.,  2., ...,  0.,  1.,  0.]))\n   1024         if sample_weight is not None:\n   1025             X, y = _rescale_data(X, y, sample_weight)\n   1026 \n   1027         centered_kernel = not sparse.issparse(X) and self.fit_intercept\n   1028 \n-> 1029         v, Q, QT_y = _pre_compute(X, y, centered_kernel)\n        v = undefined\n        Q = undefined\n        QT_y = undefined\n        _pre_compute = <bound method _RidgeGCV._pre_compute of _RidgeGC...False,\n     scoring=None, store_cv_values=False)>\n        X = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        y = array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ])\n        centered_kernel = True\n   1030         n_y = 1 if len(y.shape) == 1 else y.shape[1]\n   1031         cv_values = np.zeros((n_samples * n_y, len(self.alphas)))\n   1032         C = []\n   1033 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in _pre_compute(self=_RidgeGCV(alphas=array([  1.00000e-03,   1.00000...=False,\n     scoring=None, store_cv_values=False), X=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), y=array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ]), centered_kernel=True)\n    880         self.gcv_mode = gcv_mode\n    881         self.store_cv_values = store_cv_values\n    882 \n    883     def _pre_compute(self, X, y, centered_kernel=True):\n    884         # even if X is very sparse, K is usually very dense\n--> 885         K = safe_sparse_dot(X, X.T, dense_output=True)\n        K = undefined\n        X = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        X.T = array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]])\n    886         # the following emulates an additional constant regressor\n    887         # corresponding to fit_intercept=True\n    888         # but this is done only when the features have been centered\n    889         if centered_kernel:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py in safe_sparse_dot(a=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), b=array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]]), dense_output=True)\n    135         ret = a * b\n    136         if dense_output and hasattr(ret, \"toarray\"):\n    137             ret = ret.toarray()\n    138         return ret\n    139     else:\n--> 140         return np.dot(a, b)\n        a = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        b = array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]])\n    141 \n    142 \n    143 def randomized_range_finder(A, size, n_iter,\n    144                             power_iteration_normalizer='auto',\n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Sat Sep  1 15:11:41 2018\nPID: 14080                Python 3.6.2: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_estimators>, (3, BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), None, array([1848545992, 1844787845,  475608774]), 10), {'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_estimators>\n        args = (3, BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), None, array([1848545992, 1844787845,  475608774]), 10)\n        kwargs = {'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py in _parallel_build_estimators(n_estimators=3, ensemble=BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), X=memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), y=memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), sample_weight=None, seeds=array([1848545992, 1844787845,  475608774]), total_n_estimators=10, verbose=0)\n    107                 curr_sample_weight *= sample_counts\n    108             else:\n    109                 not_indices_mask = ~indices_to_mask(indices, n_samples)\n    110                 curr_sample_weight[not_indices_mask] = 0\n    111 \n--> 112             estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n        estimator.fit = <bound method _BaseRidgeCV.fit of RidgeCV(alphas...=False, scoring=None,\n    store_cv_values=False)>\n        X = memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]])\n        features = array([0, 1, 2, 3])\n        y = memmap([   1.,  179.,    9., ...,    6.,   26.,   16.])\n        sample_weight = None\n        curr_sample_weight = array([ 0.,  3.,  2., ...,  0.,  1.,  0.])\n    113 \n    114         # Draw samples, using a mask, and then fit\n    115         else:\n    116             estimator.fit((X[indices])[:, features], y[indices])\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in fit(self=RidgeCV(alphas=[0.001, 0.01, 0.1, 0.5, 0.75, 1, ...e=False, scoring=None,\n    store_cv_values=False), X=array([[ 3.        , -0.35095498, -0.08864828, -...       ,  0.04614738, -0.08530985, -0.27234893]]), y=memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), sample_weight=array([ 0.,  3.,  2., ...,  0.,  1.,  0.]))\n   1109                                   fit_intercept=self.fit_intercept,\n   1110                                   normalize=self.normalize,\n   1111                                   scoring=self.scoring,\n   1112                                   gcv_mode=self.gcv_mode,\n   1113                                   store_cv_values=self.store_cv_values)\n-> 1114             estimator.fit(X, y, sample_weight=sample_weight)\n        estimator.fit = <bound method _RidgeGCV.fit of _RidgeGCV(alphas=...False,\n     scoring=None, store_cv_values=False)>\n        X = array([[ 3.        , -0.35095498, -0.08864828, -...       ,  0.04614738, -0.08530985, -0.27234893]])\n        y = memmap([   1.,  179.,    9., ...,    6.,   26.,   16.])\n        sample_weight = array([ 0.,  3.,  2., ...,  0.,  1.,  0.])\n   1115             self.alpha_ = estimator.alpha_\n   1116             if self.store_cv_values:\n   1117                 self.cv_values_ = estimator.cv_values_\n   1118         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in fit(self=_RidgeGCV(alphas=array([  1.00000e-03,   1.00000...=False,\n     scoring=None, store_cv_values=False), X=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), y=array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ]), sample_weight=array([ 0.,  3.,  2., ...,  0.,  1.,  0.]))\n   1024         if sample_weight is not None:\n   1025             X, y = _rescale_data(X, y, sample_weight)\n   1026 \n   1027         centered_kernel = not sparse.issparse(X) and self.fit_intercept\n   1028 \n-> 1029         v, Q, QT_y = _pre_compute(X, y, centered_kernel)\n        v = undefined\n        Q = undefined\n        QT_y = undefined\n        _pre_compute = <bound method _RidgeGCV._pre_compute of _RidgeGC...False,\n     scoring=None, store_cv_values=False)>\n        X = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        y = array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ])\n        centered_kernel = True\n   1030         n_y = 1 if len(y.shape) == 1 else y.shape[1]\n   1031         cv_values = np.zeros((n_samples * n_y, len(self.alphas)))\n   1032         C = []\n   1033 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in _pre_compute(self=_RidgeGCV(alphas=array([  1.00000e-03,   1.00000...=False,\n     scoring=None, store_cv_values=False), X=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), y=array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ]), centered_kernel=True)\n    880         self.gcv_mode = gcv_mode\n    881         self.store_cv_values = store_cv_values\n    882 \n    883     def _pre_compute(self, X, y, centered_kernel=True):\n    884         # even if X is very sparse, K is usually very dense\n--> 885         K = safe_sparse_dot(X, X.T, dense_output=True)\n        K = undefined\n        X = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        X.T = array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]])\n    886         # the following emulates an additional constant regressor\n    887         # corresponding to fit_intercept=True\n    888         # but this is done only when the features have been centered\n    889         if centered_kernel:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py in safe_sparse_dot(a=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), b=array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]]), dense_output=True)\n    135         ret = a * b\n    136         if dense_output and hasattr(ret, \"toarray\"):\n    137             ret = ret.toarray()\n    138         return ret\n    139     else:\n--> 140         return np.dot(a, b)\n        a = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        b = array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]])\n    141 \n    142 \n    143 def randomized_range_finder(A, size, n_iter,\n    144                             power_iteration_normalizer='auto',\n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-297-2079d77a5a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaggingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \"\"\"\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 verbose=self.verbose)\n\u001b[0;32m--> 375\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000148512766F0, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000148512766F0, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 if __name__ == '__main__':\n      2     from ipykernel import kernelapp as app\n----> 3     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-09-01T15:11:07.764144', 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'session': 'E5BC9B2FE2CD4C0BB824F51A0ECDFB72', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'E5BC9B2FE2CD4C0BB824F51A0ECDFB72']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-09-01T15:11:07.764144', 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'session': 'E5BC9B2FE2CD4C0BB824F51A0ECDFB72', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'E5BC9B2FE2CD4C0BB824F51A0ECDFB72'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-09-01T15:11:07.764144', 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'session': 'E5BC9B2FE2CD4C0BB824F51A0ECDFB72', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A36E08D15AA041CB8450D6DDA5E3FD03', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\\nbg.fit(x_train,y_train)', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-297-2079d77a5a76>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 14800029e48, executio..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000014862638660, file \"<ipython-input-297-2079d77a5a76>\", line 2>\n        result = <ExecutionResult object at 14800029e48, executio..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000014862638660, file \"<ipython-input-297-2079d77a5a76>\", line 2>, result=<ExecutionResult object at 14800029e48, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000014862638660, file \"<ipython-input-297-2079d77a5a76>\", line 2>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingRegressor': <class 'sklearn.ensemble.bagging.BaggingRegressor'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'BayesianRidge': <class 'sklearn.linear_model.bayes.BayesianRidge'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import pandas as pd\\nimport matplotlib.pyplot as ...rror\\nimport xgboost as xgb\\nimport lightgbm as lgb', 'train = pd.read_csv(\"C:/Users/L3IN/Downloads/eni..._csv(\"C:/Users/L3IN/Downloads/enigma18/test.csv\")', 'train.describe()', \"train['Reputation'].idxmax()\", 'train[160728:160729]', \"train['Views'].idxmax()\", 'train[98585:98586]', \"from sklearn.preprocessing import LabelEncoder\\n\\n...['Views'] = lb_make.fit_transform(train['Views'])\", \"d = {}\\nmax_user = train['Username'].max()\\nval = ...ge(val):\\n    d[int(train.ix[i]['Username'])] += 1\", \"train['uv'] = train['Upvotes']/train['Views']\", \"v = {}\\nmax_user = train['Username'].max()\\nval = ... x1 = int(temp['Username'])\\n    v[x1] += uv/d[x1]\", \"train['upview'] = v[train['Username'].astype(int)]\", \"train['upview'] = v[train['Username']]\", \"usr = np.array(train['Username'])\", 'usr', \"train['upview'] = v[usr]\", \"train.replace({'Username': v})\", \"train['Username'].map(v)\", 'train', ...], ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingRegressor': <class 'sklearn.ensemble.bagging.BaggingRegressor'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'BayesianRidge': <class 'sklearn.linear_model.bayes.BayesianRidge'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import pandas as pd\\nimport matplotlib.pyplot as ...rror\\nimport xgboost as xgb\\nimport lightgbm as lgb', 'train = pd.read_csv(\"C:/Users/L3IN/Downloads/eni..._csv(\"C:/Users/L3IN/Downloads/enigma18/test.csv\")', 'train.describe()', \"train['Reputation'].idxmax()\", 'train[160728:160729]', \"train['Views'].idxmax()\", 'train[98585:98586]', \"from sklearn.preprocessing import LabelEncoder\\n\\n...['Views'] = lb_make.fit_transform(train['Views'])\", \"d = {}\\nmax_user = train['Username'].max()\\nval = ...ge(val):\\n    d[int(train.ix[i]['Username'])] += 1\", \"train['uv'] = train['Upvotes']/train['Views']\", \"v = {}\\nmax_user = train['Username'].max()\\nval = ... x1 = int(temp['Username'])\\n    v[x1] += uv/d[x1]\", \"train['upview'] = v[train['Username'].astype(int)]\", \"train['upview'] = v[train['Username']]\", \"usr = np.array(train['Username'])\", 'usr', \"train['upview'] = v[usr]\", \"train.replace({'Username': v})\", \"train['Username'].map(v)\", 'train', ...], ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\L3IN\\Downloads\\enigma18\\<ipython-input-297-2079d77a5a76> in <module>()\n      1 bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\n----> 2 bg.fit(x_train,y_train)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py in fit(self=BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), X=        Tag     Views       new  Reputation\n3241... -0.085310   -0.272349\n\n[297040 rows x 4 columns], y=        Upvotes\n324119      1.0\n146493    179.0\n...  26.0\n305711     16.0\n\n[297040 rows x 1 columns], sample_weight=None)\n    242         Returns\n    243         -------\n    244         self : object\n    245             Returns self.\n    246         \"\"\"\n--> 247         return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n        self._fit = <bound method BaseBagging._fit of BaggingRegress... random_state=None, verbose=0, warm_start=False)>\n        X =         Tag     Views       new  Reputation\n3241... -0.085310   -0.272349\n\n[297040 rows x 4 columns]\n        y =         Upvotes\n324119      1.0\n146493    179.0\n...  26.0\n305711     16.0\n\n[297040 rows x 1 columns]\n        self.max_samples = 1.0\n        sample_weight = None\n    248 \n    249     def _fit(self, X, y, max_samples=None, max_depth=None, sample_weight=None):\n    250         \"\"\"Build a Bagging ensemble of estimators from the training\n    251            set (X, y).\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py in _fit(self=BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), X=array([[ 3.        , -0.35095498, -0.08864828, -...       ,  0.04614738, -0.08530985, -0.27234893]]), y=array([   1.,  179.,    9., ...,    6.,   26.,   16.]), max_samples=297040, max_depth=None, sample_weight=None)\n    370                 y,\n    371                 sample_weight,\n    372                 seeds[starts[i]:starts[i + 1]],\n    373                 total_n_estimators,\n    374                 verbose=self.verbose)\n--> 375             for i in range(n_jobs))\n        n_jobs = 4\n    376 \n    377         # Reduce\n    378         self.estimators_ += list(itertools.chain.from_iterable(\n    379             t[0] for t in all_results))\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseBagging._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Sat Sep  1 15:11:41 2018\nPID: 14080                Python 3.6.2: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_estimators>, (3, BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), None, array([1848545992, 1844787845,  475608774]), 10), {'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_estimators>\n        args = (3, BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), None, array([1848545992, 1844787845,  475608774]), 10)\n        kwargs = {'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py in _parallel_build_estimators(n_estimators=3, ensemble=BaggingRegressor(base_estimator=RidgeCV(alphas=[...  random_state=None, verbose=0, warm_start=False), X=memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]]), y=memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), sample_weight=None, seeds=array([1848545992, 1844787845,  475608774]), total_n_estimators=10, verbose=0)\n    107                 curr_sample_weight *= sample_counts\n    108             else:\n    109                 not_indices_mask = ~indices_to_mask(indices, n_samples)\n    110                 curr_sample_weight[not_indices_mask] = 0\n    111 \n--> 112             estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n        estimator.fit = <bound method _BaseRidgeCV.fit of RidgeCV(alphas...=False, scoring=None,\n    store_cv_values=False)>\n        X = memmap([[ 3.        , -0.35095498, -0.08864828, ...       ,  0.04614738, -0.08530985, -0.27234893]])\n        features = array([0, 1, 2, 3])\n        y = memmap([   1.,  179.,    9., ...,    6.,   26.,   16.])\n        sample_weight = None\n        curr_sample_weight = array([ 0.,  3.,  2., ...,  0.,  1.,  0.])\n    113 \n    114         # Draw samples, using a mask, and then fit\n    115         else:\n    116             estimator.fit((X[indices])[:, features], y[indices])\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in fit(self=RidgeCV(alphas=[0.001, 0.01, 0.1, 0.5, 0.75, 1, ...e=False, scoring=None,\n    store_cv_values=False), X=array([[ 3.        , -0.35095498, -0.08864828, -...       ,  0.04614738, -0.08530985, -0.27234893]]), y=memmap([   1.,  179.,    9., ...,    6.,   26.,   16.]), sample_weight=array([ 0.,  3.,  2., ...,  0.,  1.,  0.]))\n   1109                                   fit_intercept=self.fit_intercept,\n   1110                                   normalize=self.normalize,\n   1111                                   scoring=self.scoring,\n   1112                                   gcv_mode=self.gcv_mode,\n   1113                                   store_cv_values=self.store_cv_values)\n-> 1114             estimator.fit(X, y, sample_weight=sample_weight)\n        estimator.fit = <bound method _RidgeGCV.fit of _RidgeGCV(alphas=...False,\n     scoring=None, store_cv_values=False)>\n        X = array([[ 3.        , -0.35095498, -0.08864828, -...       ,  0.04614738, -0.08530985, -0.27234893]])\n        y = memmap([   1.,  179.,    9., ...,    6.,   26.,   16.])\n        sample_weight = array([ 0.,  3.,  2., ...,  0.,  1.,  0.])\n   1115             self.alpha_ = estimator.alpha_\n   1116             if self.store_cv_values:\n   1117                 self.cv_values_ = estimator.cv_values_\n   1118         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in fit(self=_RidgeGCV(alphas=array([  1.00000e-03,   1.00000...=False,\n     scoring=None, store_cv_values=False), X=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), y=array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ]), sample_weight=array([ 0.,  3.,  2., ...,  0.,  1.,  0.]))\n   1024         if sample_weight is not None:\n   1025             X, y = _rescale_data(X, y, sample_weight)\n   1026 \n   1027         centered_kernel = not sparse.issparse(X) and self.fit_intercept\n   1028 \n-> 1029         v, Q, QT_y = _pre_compute(X, y, centered_kernel)\n        v = undefined\n        Q = undefined\n        QT_y = undefined\n        _pre_compute = <bound method _RidgeGCV._pre_compute of _RidgeGC...False,\n     scoring=None, store_cv_values=False)>\n        X = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        y = array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ])\n        centered_kernel = True\n   1030         n_y = 1 if len(y.shape) == 1 else y.shape[1]\n   1031         cv_values = np.zeros((n_samples * n_y, len(self.alphas)))\n   1032         C = []\n   1033 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py in _pre_compute(self=_RidgeGCV(alphas=array([  1.00000e-03,   1.00000...=False,\n     scoring=None, store_cv_values=False), X=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), y=array([   0.        , -293.31976046, -479.910887...0.        ,\n       -322.34824266,    0.        ]), centered_kernel=True)\n    880         self.gcv_mode = gcv_mode\n    881         self.store_cv_values = store_cv_values\n    882 \n    883     def _pre_compute(self, X, y, centered_kernel=True):\n    884         # even if X is very sparse, K is usually very dense\n--> 885         K = safe_sparse_dot(X, X.T, dense_output=True)\n        K = undefined\n        X = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        X.T = array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]])\n    886         # the following emulates an additional constant regressor\n    887         # corresponding to fit_intercept=True\n    888         # but this is done only when the features have been centered\n    889         if centered_kernel:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py in safe_sparse_dot(a=array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]]), b=array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]]), dense_output=True)\n    135         ret = a * b\n    136         if dense_output and hasattr(ret, \"toarray\"):\n    137             ret = ret.toarray()\n    138         return ret\n    139     else:\n--> 140         return np.dot(a, b)\n        a = array([[ 0.        ,  0.        ,  0.        ,  ...       ,  0.        ,  0.        ,  0.        ]])\n        b = array([[ 0.        ,  0.78514311,  3.46949379, ....  0.        ,\n        -0.23739107,  0.        ]])\n    141 \n    142 \n    143 def randomized_range_finder(A, size, n_iter,\n    144                             power_iteration_normalizer='auto',\n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "bg = BaggingRegressor(ridge, n_estimators=10, n_jobs=-1)\n",
    "bg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_20 = train.loc[train['Upvotes'] <= 20, 'Upvotes'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.846120204923154"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = []\n",
    "\n",
    "for i in y_pred:\n",
    "    if i[0] < 0:\n",
    "        i[0] = mean_20\n",
    "    ans.append(i[0])\n",
    "               \n",
    "ans = np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 226.94482383,   92.61290065,   37.59997065, ...,   87.27893992,\n",
       "          0.98643793,   19.31768499])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\n",
    "    'ID' : test['ID'],\n",
    "    'Upvotes' : ans\n",
    "})\n",
    "sub.to_csv('C:/Users/L3IN/Downloads/enigma18/sub14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ans < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
